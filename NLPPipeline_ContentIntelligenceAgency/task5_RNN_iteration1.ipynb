{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab Task 5: Model Iterations (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the Notebook\n",
    "\n",
    "This notebook focuses on building and evaluating a Recurrent Neural Network (RNN) model for emotion classification based on extracted NLP features. The workflow includes:\n",
    "\n",
    "1. **Data Preparation**: Loading and preprocessing features such as TF-IDF, pretrained embeddings, custom embeddings, and other numerical features. The target labels are encoded for classification.\n",
    "2. **Feature Engineering**: Combining all features into a single dataset and normalizing them for model training.\n",
    "3. **Model Development**: Constructing an RNN model with multiple layers, including SimpleRNN, BatchNormalization, Dropout, and Dense layers.\n",
    "4. **Training and Evaluation**: Training the model with callbacks for early stopping, model checkpointing, and F1-score monitoring. The model's performance is evaluated using metrics like accuracy, F1-score, confusion matrix, and classification report.\n",
    "\n",
    "### Observations\n",
    "The model exhibits signs of overfitting, as indicated by a significant gap between training and validation performance. This suggests that the model is learning the training data well but struggles to generalize to unseen data. Potential remedies include reducing model complexity, increasing dropout rates, or using regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS_Tags</th>\n",
       "      <th>TF_IDF</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Pretrained_Embeddings</th>\n",
       "      <th>Custom_Embeddings</th>\n",
       "      <th>Sentiment_Exclamations_Questions</th>\n",
       "      <th>Personal_Pronoun_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vous êtes embrassés?</td>\n",
       "      <td>Vous_PRON êtes_AUX embrassés_VERB ?_PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[ 0.044216   -0.0278645  -0.032453   -0.030573...</td>\n",
       "      <td>[ 5.27364027e-04  5.90693962e-04  3.06792255e-...</td>\n",
       "      <td>0.0,0,1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oui.</td>\n",
       "      <td>Oui_ADV ._PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[-3.2684386e-03  4.5674204e-04 -2.1957180e-03 ...</td>\n",
       "      <td>0.0,0,0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mais non!</td>\n",
       "      <td>Mais_CCONJ non_ADV !_PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>[ 1.6874e-01  6.2667e-03 -7.5556e-02 -8.9906e-...</td>\n",
       "      <td>[ 1.61075848e-03  3.01836710e-03  2.69862730e-...</td>\n",
       "      <td>0.0,1,0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vous êtes embrassés?</td>\n",
       "      <td>Vous_PRON êtes_AUX embrassés_VERB ?_PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[ 0.044216   -0.0278645  -0.032453   -0.030573...</td>\n",
       "      <td>[ 5.27364027e-04  5.90693962e-04  3.06792255e-...</td>\n",
       "      <td>0.0,0,1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oui.</td>\n",
       "      <td>Oui_ADV ._PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[-3.2684386e-03  4.5674204e-04 -2.1957180e-03 ...</td>\n",
       "      <td>0.0,0,0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence                                   POS_Tags  \\\n",
       "0  Vous êtes embrassés?  Vous_PRON êtes_AUX embrassés_VERB ?_PUNCT   \n",
       "1                  Oui.                            Oui_ADV ._PUNCT   \n",
       "2             Mais non!                 Mais_CCONJ non_ADV !_PUNCT   \n",
       "3  Vous êtes embrassés?  Vous_PRON êtes_AUX embrassés_VERB ?_PUNCT   \n",
       "4                  Oui.                            Oui_ADV ._PUNCT   \n",
       "\n",
       "                    TF_IDF  Sentiment_Score  \\\n",
       "0  [0. 0. 0. ... 0. 0. 0.]           0.0000   \n",
       "1  [0. 0. 0. ... 0. 0. 0.]           0.0100   \n",
       "2  [0. 0. 0. ... 0. 0. 0.]          -0.0125   \n",
       "3  [0. 0. 0. ... 0. 0. 0.]           0.0000   \n",
       "4  [0. 0. 0. ... 0. 0. 0.]           0.0100   \n",
       "\n",
       "                               Pretrained_Embeddings  \\\n",
       "0  [ 0.044216   -0.0278645  -0.032453   -0.030573...   \n",
       "1  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...   \n",
       "2  [ 1.6874e-01  6.2667e-03 -7.5556e-02 -8.9906e-...   \n",
       "3  [ 0.044216   -0.0278645  -0.032453   -0.030573...   \n",
       "4  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...   \n",
       "\n",
       "                                   Custom_Embeddings  \\\n",
       "0  [ 5.27364027e-04  5.90693962e-04  3.06792255e-...   \n",
       "1  [-3.2684386e-03  4.5674204e-04 -2.1957180e-03 ...   \n",
       "2  [ 1.61075848e-03  3.01836710e-03  2.69862730e-...   \n",
       "3  [ 5.27364027e-04  5.90693962e-04  3.06792255e-...   \n",
       "4  [-3.2684386e-03  4.5674204e-04 -2.1957180e-03 ...   \n",
       "\n",
       "  Sentiment_Exclamations_Questions  Personal_Pronoun_Count  \n",
       "0                          0.0,0,1                       1  \n",
       "1                          0.0,0,0                       0  \n",
       "2                          0.0,1,0                       0  \n",
       "3                          0.0,0,1                       1  \n",
       "4                          0.0,0,0                       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the dataset with extracted features\n",
    "features = \"NLP_features.xlsx\"\n",
    "df = pd.read_excel(features)\n",
    "\n",
    "# Display dataset structure in table format\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisf\\AppData\\Local\\Temp\\ipykernel_31364\\2270948474.py:2: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  df[\"TF_IDF\"] = df[\"TF_IDF\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Convert TF-IDF features\n",
    "df[\"TF_IDF\"] = df[\"TF_IDF\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x)\n",
    "tfidf_features = np.array(df[\"TF_IDF\"].tolist())\n",
    "if len(tfidf_features.shape) == 1:\n",
    "    tfidf_features = tfidf_features.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings\n",
    "df[\"Pretrained_Embeddings\"] = df[\"Pretrained_Embeddings\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x)\n",
    "df[\"Custom_Embeddings\"] = df[\"Custom_Embeddings\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x)\n",
    "pretrained_embeddings = np.array(df[\"Pretrained_Embeddings\"].tolist())\n",
    "custom_embeddings = np.array(df[\"Custom_Embeddings\"].tolist())\n",
    "if len(pretrained_embeddings.shape) == 1:\n",
    "    pretrained_embeddings = pretrained_embeddings.reshape(-1, 1)\n",
    "if len(custom_embeddings.shape) == 1:\n",
    "    custom_embeddings = custom_embeddings.reshape(-1, 1)\n",
    "\n",
    "# Convert other numerical features\n",
    "df[\"Sentiment_Score\"] = df[\"Sentiment_Score\"].astype(float)\n",
    "df[\"Personal_Pronoun_Count\"] = df[\"Personal_Pronoun_Count\"].astype(float)\n",
    "other_features = df[[\"Sentiment_Score\", \"Personal_Pronoun_Count\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Emotion_Label\"] = label_encoder.fit_transform(df[\"Sentiment_Exclamations_Questions\"])\n",
    "\n",
    "# Combine all features\n",
    "X = np.hstack((tfidf_features, pretrained_embeddings, custom_embeddings, other_features))\n",
    "y = df[\"Emotion_Label\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for RNN\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Convert labels to categorical\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_categorical = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisf\\anaconda3\\envs\\blockc_y2\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build RNN model\n",
    "model = Sequential([\n",
    "    SimpleRNN(128, return_sequences=True, input_shape=(1, X_train_scaled.shape[1])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    SimpleRNN(64, return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define F1-score callback\n",
    "class F1ScoreCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(X_test_reshaped), axis=1)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f' - F1 Score: {f1:.4f}')\n",
    "\n",
    "# Set callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_rnn_model.h5', save_best_only=True),\n",
    "    F1ScoreCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3593 - loss: 2.0894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      " - F1 Score: 0.8778\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.4114 - loss: 1.9761 - val_accuracy: 0.9018 - val_loss: 1.1878\n",
      "Epoch 2/50\n",
      "\u001b[1m17/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8594 - loss: 0.8765 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.8878\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8647 - loss: 0.8497 - val_accuracy: 0.9202 - val_loss: 0.7133\n",
      "Epoch 3/50\n",
      "\u001b[1m16/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.5318 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9017 - loss: 0.5103 - val_accuracy: 0.9325 - val_loss: 0.5465\n",
      "Epoch 4/50\n",
      "\u001b[1m15/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9216 - loss: 0.3944 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      " - F1 Score: 0.8980\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9275 - loss: 0.3714 - val_accuracy: 0.9202 - val_loss: 0.4805\n",
      "Epoch 5/50\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.2149 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      " - F1 Score: 0.8924\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9615 - loss: 0.2220 - val_accuracy: 0.9141 - val_loss: 0.4496\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9497 - loss: 0.2471\n",
      " - F1 Score: 0.8924\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9503 - loss: 0.2428 - val_accuracy: 0.9141 - val_loss: 0.4507\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9644 - loss: 0.1883\n",
      " - F1 Score: 0.8999\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9635 - loss: 0.1902 - val_accuracy: 0.9202 - val_loss: 0.4503\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9405 - loss: 0.2227\n",
      " - F1 Score: 0.8999\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9452 - loss: 0.2103 - val_accuracy: 0.9202 - val_loss: 0.4771\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9605 - loss: 0.1400\n",
      " - F1 Score: 0.8980\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.1423 - val_accuracy: 0.9202 - val_loss: 0.4799\n",
      "Epoch 10/50\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1576 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      " - F1 Score: 0.8999\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9576 - loss: 0.1555 - val_accuracy: 0.9202 - val_loss: 0.4431\n",
      "Epoch 11/50\n",
      "\u001b[1m19/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.1023 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.8999\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9727 - loss: 0.1040 - val_accuracy: 0.9202 - val_loss: 0.4401\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9657 - loss: 0.1176\n",
      " - F1 Score: 0.8999\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9660 - loss: 0.1178 - val_accuracy: 0.9202 - val_loss: 0.4890\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9877 - loss: 0.0866\n",
      " - F1 Score: 0.8999\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0918 - val_accuracy: 0.9202 - val_loss: 0.4857\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step p - accuracy: 0.9727 - loss: 0.1034\n",
      " - F1 Score: 0.9055\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9732 - loss: 0.1045 - val_accuracy: 0.9264 - val_loss: 0.4868\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9857 - loss: 0.0701\n",
      " - F1 Score: 0.9055\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9834 - loss: 0.0749 - val_accuracy: 0.9264 - val_loss: 0.5201\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9668 - loss: 0.0927\n",
      " - F1 Score: 0.9061\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9693 - loss: 0.0886 - val_accuracy: 0.9264 - val_loss: 0.4869\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_reshaped, y_train_categorical,\n",
    "    validation_data=(X_test_reshaped, y_test_categorical),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test, final_predictions, target_names=label_encoder.classes_)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Final F1 Score: 0.8999\n"
     ]
    }
   ],
   "source": [
    "# Evaluate final model\n",
    "final_predictions = np.argmax(model.predict(X_test_reshaped), axis=1)\n",
    "final_f1 = f1_score(y_test, final_predictions, average='weighted')\n",
    "print(f'Final F1 Score: {final_f1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blockc_y2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
