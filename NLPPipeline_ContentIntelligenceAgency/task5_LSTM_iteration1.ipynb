{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab Task 5: Model Iterations (LSTM)\n",
    "\n",
    "First iteration on the model. Unvalid due to overfitting as shown at the end.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the Notebook\n",
    "\n",
    "This notebook focuses on building and evaluating an LSTM-based model for emotion classification using NLP features. The steps include:\n",
    "\n",
    "1. Importing necessary libraries and loading the dataset.\n",
    "2. Preprocessing features such as TF-IDF, embeddings, and other numerical data.\n",
    "3. Encoding target labels and combining all features into a single dataset.\n",
    "4. Splitting the data into training and testing sets and normalizing the features.\n",
    "5. Reshaping the data for LSTM input and converting labels to categorical format.\n",
    "6. Building and compiling an LSTM model with dropout and batch normalization layers.\n",
    "7. Training the model with callbacks for early stopping, model checkpointing, and F1-score evaluation.\n",
    "8. Evaluating the final model's performance using the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS_Tags</th>\n",
       "      <th>TF_IDF</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Pretrained_Embeddings</th>\n",
       "      <th>Custom_Embeddings</th>\n",
       "      <th>Sentiment_Exclamations_Questions</th>\n",
       "      <th>Personal_Pronoun_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vous êtes embrassés?</td>\n",
       "      <td>Vous_PRON êtes_AUX embrassés_VERB ?_PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[ 0.044216   -0.0278645  -0.032453   -0.030573...</td>\n",
       "      <td>[ 5.27364027e-04  5.90693962e-04  3.06792255e-...</td>\n",
       "      <td>0.0,0,1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oui.</td>\n",
       "      <td>Oui_ADV ._PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[-3.2684386e-03  4.5674204e-04 -2.1957180e-03 ...</td>\n",
       "      <td>0.0,0,0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mais non!</td>\n",
       "      <td>Mais_CCONJ non_ADV !_PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>[ 1.6874e-01  6.2667e-03 -7.5556e-02 -8.9906e-...</td>\n",
       "      <td>[ 1.61075848e-03  3.01836710e-03  2.69862730e-...</td>\n",
       "      <td>0.0,1,0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vous êtes embrassés?</td>\n",
       "      <td>Vous_PRON êtes_AUX embrassés_VERB ?_PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[ 0.044216   -0.0278645  -0.032453   -0.030573...</td>\n",
       "      <td>[ 5.27364027e-04  5.90693962e-04  3.06792255e-...</td>\n",
       "      <td>0.0,0,1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oui.</td>\n",
       "      <td>Oui_ADV ._PUNCT</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[-3.2684386e-03  4.5674204e-04 -2.1957180e-03 ...</td>\n",
       "      <td>0.0,0,0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence                                   POS_Tags  \\\n",
       "0  Vous êtes embrassés?  Vous_PRON êtes_AUX embrassés_VERB ?_PUNCT   \n",
       "1                  Oui.                            Oui_ADV ._PUNCT   \n",
       "2             Mais non!                 Mais_CCONJ non_ADV !_PUNCT   \n",
       "3  Vous êtes embrassés?  Vous_PRON êtes_AUX embrassés_VERB ?_PUNCT   \n",
       "4                  Oui.                            Oui_ADV ._PUNCT   \n",
       "\n",
       "                    TF_IDF  Sentiment_Score  \\\n",
       "0  [0. 0. 0. ... 0. 0. 0.]           0.0000   \n",
       "1  [0. 0. 0. ... 0. 0. 0.]           0.0100   \n",
       "2  [0. 0. 0. ... 0. 0. 0.]          -0.0125   \n",
       "3  [0. 0. 0. ... 0. 0. 0.]           0.0000   \n",
       "4  [0. 0. 0. ... 0. 0. 0.]           0.0100   \n",
       "\n",
       "                               Pretrained_Embeddings  \\\n",
       "0  [ 0.044216   -0.0278645  -0.032453   -0.030573...   \n",
       "1  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...   \n",
       "2  [ 1.6874e-01  6.2667e-03 -7.5556e-02 -8.9906e-...   \n",
       "3  [ 0.044216   -0.0278645  -0.032453   -0.030573...   \n",
       "4  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...   \n",
       "\n",
       "                                   Custom_Embeddings  \\\n",
       "0  [ 5.27364027e-04  5.90693962e-04  3.06792255e-...   \n",
       "1  [-3.2684386e-03  4.5674204e-04 -2.1957180e-03 ...   \n",
       "2  [ 1.61075848e-03  3.01836710e-03  2.69862730e-...   \n",
       "3  [ 5.27364027e-04  5.90693962e-04  3.06792255e-...   \n",
       "4  [-3.2684386e-03  4.5674204e-04 -2.1957180e-03 ...   \n",
       "\n",
       "  Sentiment_Exclamations_Questions  Personal_Pronoun_Count  \n",
       "0                          0.0,0,1                       1  \n",
       "1                          0.0,0,0                       0  \n",
       "2                          0.0,1,0                       0  \n",
       "3                          0.0,0,1                       1  \n",
       "4                          0.0,0,0                       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the dataset with extracted features\n",
    "features = \"NLP_features.xlsx\"\n",
    "df = pd.read_excel(features)\n",
    "\n",
    "# Display dataset structure in table format\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisf\\AppData\\Local\\Temp\\ipykernel_26784\\2270948474.py:2: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  df[\"TF_IDF\"] = df[\"TF_IDF\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Convert TF-IDF features\n",
    "df[\"TF_IDF\"] = df[\"TF_IDF\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x)\n",
    "tfidf_features = np.array(df[\"TF_IDF\"].tolist())\n",
    "if len(tfidf_features.shape) == 1:\n",
    "    tfidf_features = tfidf_features.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings\n",
    "df[\"Pretrained_Embeddings\"] = df[\"Pretrained_Embeddings\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x)\n",
    "df[\"Custom_Embeddings\"] = df[\"Custom_Embeddings\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x)\n",
    "pretrained_embeddings = np.array(df[\"Pretrained_Embeddings\"].tolist())\n",
    "custom_embeddings = np.array(df[\"Custom_Embeddings\"].tolist())\n",
    "if len(pretrained_embeddings.shape) == 1:\n",
    "    pretrained_embeddings = pretrained_embeddings.reshape(-1, 1)\n",
    "if len(custom_embeddings.shape) == 1:\n",
    "    custom_embeddings = custom_embeddings.reshape(-1, 1)\n",
    "\n",
    "# Convert other numerical features\n",
    "df[\"Sentiment_Score\"] = df[\"Sentiment_Score\"].astype(float)\n",
    "df[\"Personal_Pronoun_Count\"] = df[\"Personal_Pronoun_Count\"].astype(float)\n",
    "other_features = df[[\"Sentiment_Score\", \"Personal_Pronoun_Count\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Emotion_Label\"] = label_encoder.fit_transform(df[\"Sentiment_Exclamations_Questions\"])\n",
    "\n",
    "# Combine all features\n",
    "X = np.hstack((tfidf_features, pretrained_embeddings, custom_embeddings, other_features))\n",
    "y = df[\"Emotion_Label\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Convert labels to categorical\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_categorical = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisf\\anaconda3\\envs\\blockc_y2\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(1, X_train_scaled.shape[1])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define F1-score callback\n",
    "class F1ScoreCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(X_test_reshaped), axis=1)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f' - F1 Score: {f1:.4f}')\n",
    "\n",
    "# Set callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_lstm_model.h5', save_best_only=True),\n",
    "    F1ScoreCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/21\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0360 - loss: 2.8653     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      " - F1 Score: 0.8782\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.0862 - loss: 2.7119 - val_accuracy: 0.9080 - val_loss: 2.5634\n",
      "Epoch 2/50\n",
      "\u001b[1m14/21\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6436 - loss: 1.4817 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      " - F1 Score: 0.8938\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6919 - loss: 1.3809 - val_accuracy: 0.9202 - val_loss: 2.2337\n",
      "Epoch 3/50\n",
      "\u001b[1m12/21\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.7203 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.8938\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9144 - loss: 0.6653 - val_accuracy: 0.9202 - val_loss: 1.8667\n",
      "Epoch 4/50\n",
      "\u001b[1m12/21\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.3536 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.9004\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9470 - loss: 0.3448 - val_accuracy: 0.9264 - val_loss: 1.6118\n",
      "Epoch 5/50\n",
      "\u001b[1m13/21\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.2108 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.9004\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9597 - loss: 0.2317 - val_accuracy: 0.9264 - val_loss: 1.3930\n",
      "Epoch 6/50\n",
      "\u001b[1m13/21\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.2202 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9598 - loss: 0.2124 - val_accuracy: 0.9325 - val_loss: 1.1844\n",
      "Epoch 7/50\n",
      "\u001b[1m13/21\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.1762 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9644 - loss: 0.1747 - val_accuracy: 0.9325 - val_loss: 0.9547\n",
      "Epoch 8/50\n",
      "\u001b[1m13/21\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9624 - loss: 0.1723 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9652 - loss: 0.1664 - val_accuracy: 0.9325 - val_loss: 0.7811\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 0.0906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9850 - loss: 0.0920 - val_accuracy: 0.9325 - val_loss: 0.6582\n",
      "Epoch 10/50\n",
      "\u001b[1m11/21\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.1563 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9684 - loss: 0.1438 - val_accuracy: 0.9325 - val_loss: 0.5349\n",
      "Epoch 11/50\n",
      "\u001b[1m12/21\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9744 - loss: 0.1198 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9737 - loss: 0.1142 - val_accuracy: 0.9325 - val_loss: 0.4724\n",
      "Epoch 12/50\n",
      "\u001b[1m12/21\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.0905 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      " - F1 Score: 0.9038\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9758 - loss: 0.0997 - val_accuracy: 0.9264 - val_loss: 0.4430\n",
      "Epoch 13/50\n",
      "\u001b[1m13/21\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9700 - loss: 0.0788 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9735 - loss: 0.0766 - val_accuracy: 0.9325 - val_loss: 0.4280\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9871 - loss: 0.0620\n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0699 - val_accuracy: 0.9325 - val_loss: 0.4341\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9881 - loss: 0.0465\n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0540 - val_accuracy: 0.9325 - val_loss: 0.4376\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9778 - loss: 0.0508\n",
      " - F1 Score: 0.9038\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9800 - loss: 0.0563 - val_accuracy: 0.9264 - val_loss: 0.4557\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step p - accuracy: 0.9933 - loss: 0.0556\n",
      " - F1 Score: 0.9038\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9936 - loss: 0.0524 - val_accuracy: 0.9264 - val_loss: 0.4961\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step p - accuracy: 0.9855 - loss: 0.0446\n",
      " - F1 Score: 0.9098\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9868 - loss: 0.0438 - val_accuracy: 0.9325 - val_loss: 0.5013\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_reshaped, y_train_categorical,\n",
    "    validation_data=(X_test_reshaped, y_test_categorical),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Final F1 Score: 0.9098\n"
     ]
    }
   ],
   "source": [
    "# Evaluate final model\n",
    "final_predictions = np.argmax(model.predict(X_test_reshaped), axis=1)\n",
    "final_f1 = f1_score(y_test, final_predictions, average='weighted')\n",
    "print(f'Final F1 Score: {final_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Improvements and Choices for Emotion Classification\n",
    "\n",
    "To improve model performance, we used TF-IDF, pretrained, and custom embeddings combined with numerical features. An LSTM model with dropout and batch normalization was built to prevent overfitting. Early stopping and model checkpointing ensured optimal training.\n",
    "\n",
    "These choices align with the task of emotion classification in spoken language by leveraging embeddings for semantic understanding and numerical features for context. The LSTM architecture captures sequential dependencies, crucial for spoken language. Dropout and batch normalization address overfitting, ensuring robustness across diverse language patterns and domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blockc_y2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
