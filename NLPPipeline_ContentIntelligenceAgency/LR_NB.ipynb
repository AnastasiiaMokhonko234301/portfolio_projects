{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd88e6d6-013f-43d7-bed8-8c3122984e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6ccfac-4df4-40fd-ae99-57c981f4b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Safe vector parser\n",
    "def parse_vector(v):\n",
    "    if isinstance(v, str):\n",
    "        return list(map(float, re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", v)))\n",
    "    return v\n",
    "\n",
    "def safe_vector_list(series, expected_dim):\n",
    "    return np.vstack(series.apply(parse_vector).apply(lambda x: x if len(x) == expected_dim else np.zeros(expected_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45bdc513-dd5e-464d-a8a6-c328549f9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load training data\n",
    "df = pd.read_csv(\"NLP_features(lr_nb).csv\")\n",
    "df[\"TF_IDF\"] = df[\"TF_IDF\"].apply(parse_vector)\n",
    "df[\"Pretrained_Embeddings\"] = df[\"Pretrained_Embeddings\"].apply(parse_vector)\n",
    "df[\"Custom_Embeddings\"] = df[\"Custom_Embeddings\"].apply(parse_vector)\n",
    "df[\"POS_Tags\"] = df[\"POS_Tags\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba86584-22b9-4289-a73c-5d53cb620ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Encode labels\n",
    "label_encoder_emotion = LabelEncoder()\n",
    "df[\"emotion_label\"] = label_encoder_emotion.fit_transform(df[\"Emotion\"])\n",
    "emotion_classes = label_encoder_emotion.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e879b750-cfe0-4159-896b-1078121285f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Features\n",
    "tfidf_features = safe_vector_list(df[\"TF_IDF\"], expected_dim=100)\n",
    "pretrained_embeddings = safe_vector_list(df[\"Pretrained_Embeddings\"], expected_dim=300)\n",
    "custom_embeddings = safe_vector_list(df[\"Custom_Embeddings\"], expected_dim=300)\n",
    "pos_mlb = MultiLabelBinarizer()\n",
    "pos_encoded = pos_mlb.fit_transform(df[\"POS_Tags\"])\n",
    "extra_features = df[[\n",
    "    \"Sentiment_Score\", \"Polarity\", \"Subjectivity\",\n",
    "    \"Exclamations\", \"Is_Question\", \"Personal_Pronoun_Count\"\n",
    "]].apply(pd.to_numeric, errors=\"coerce\").fillna(0).values\n",
    "\n",
    "X_raw = np.hstack([tfidf_features, pos_encoded, extra_features, pretrained_embeddings, custom_embeddings])\n",
    "y = df[\"emotion_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be086bf1-0ce6-4f21-81c5-4e537e34fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Scale + split\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train_raw, X_val_raw, _, _ = train_test_split(X_raw, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5086564-110f-439d-ac52-03f3e001f8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7. Logistic Regression grid search\n",
    "param_grid_lr = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"solver\": [\"saga\"],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"max_iter\": [2000],\n",
    "    \"class_weight\": [\"balanced\"]\n",
    "}\n",
    "lr_search = GridSearchCV(LogisticRegression(), param_grid_lr, scoring=\"f1_weighted\", cv=3, n_jobs=-1, verbose=1)\n",
    "lr_search.fit(X_train, y_train)\n",
    "best_lr = lr_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5a5b88-340b-406f-900d-0b7af0e3624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "# 8. Naive Bayes grid search (on raw, non-negative)\n",
    "X_train_nb = X_train_raw.clip(min=0)\n",
    "X_val_nb = X_val_raw.clip(min=0)\n",
    "param_grid_nb = { \"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0] }\n",
    "nb_search = GridSearchCV(MultinomialNB(), param_grid_nb, scoring=\"f1_weighted\", cv=3, n_jobs=-1, verbose=1)\n",
    "nb_search.fit(X_train_nb, y_train)\n",
    "best_nb = nb_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "260acc4b-c3c7-4c50-b6fa-1a1c08c8c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Load & process test data\n",
    "df_test = pd.read_csv(\"NLP_test(lr_nb).csv\")\n",
    "df_test = df_test[~df_test[\"Emotion\"].isin([\"[]\", \"\", None])].copy()\n",
    "df_test[\"emotion_label\"] = label_encoder_emotion.transform(df_test[\"Emotion\"])\n",
    "df_test[\"TF_IDF\"] = df_test[\"TF_IDF\"].apply(parse_vector)\n",
    "df_test[\"Pretrained_Embeddings\"] = df_test[\"Pretrained_Embeddings\"].apply(parse_vector)\n",
    "df_test[\"Custom_Embeddings\"] = df_test[\"Custom_Embeddings\"].apply(parse_vector)\n",
    "df_test[\"POS_Tags\"] = df_test[\"POS_Tags\"].apply(eval)\n",
    "\n",
    "test_tfidf = safe_vector_list(df_test[\"TF_IDF\"], expected_dim=100)\n",
    "test_pretrained = safe_vector_list(df_test[\"Pretrained_Embeddings\"], expected_dim=300)\n",
    "test_custom = safe_vector_list(df_test[\"Custom_Embeddings\"], expected_dim=300)\n",
    "test_pos = pos_mlb.transform(df_test[\"POS_Tags\"])\n",
    "test_extra = df_test[[\n",
    "    \"Sentiment_Score\", \"Polarity\", \"Subjectivity\",\n",
    "    \"Exclamations\", \"Is_Question\", \"Personal_Pronoun_Count\"\n",
    "]].apply(pd.to_numeric, errors=\"coerce\").fillna(0).values\n",
    "\n",
    "X_test_raw = np.hstack([test_tfidf, test_pos, test_extra, test_pretrained, test_custom])\n",
    "X_test_scaled = scaler.transform(X_test_raw)\n",
    "y_test = df_test[\"emotion_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed0401a4-601f-4886-9cff-d80de3996859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Evaluation helper\n",
    "def evaluate(name, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f\"\\nðŸ“Š {name} Set\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=emotion_classes, zero_division=0))\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d34dcb-bad2-447e-8fc1-e1f8dd970ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Predict\n",
    "val_preds_lr = best_lr.predict(X_val)\n",
    "test_preds_lr = best_lr.predict(X_test_scaled)\n",
    "\n",
    "val_preds_nb = best_nb.predict(X_val_nb)\n",
    "test_preds_nb = best_nb.predict(X_test_raw.clip(min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a71b59de-507c-4023-9c05-eeb8bcd1826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Validation (LogReg) Set\n",
      "Accuracy:  0.7691\n",
      "F1 Score:  0.7674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.70      0.81      0.75        68\n",
      "     disgust       0.78      0.85      0.81        61\n",
      "        fear       0.81      0.84      0.82        73\n",
      "   happiness       0.76      0.64      0.69       105\n",
      "     neutral       0.79      0.72      0.76       154\n",
      "     sadness       0.73      0.89      0.80        62\n",
      "    surprise       0.79      0.78      0.79        79\n",
      "\n",
      "    accuracy                           0.77       602\n",
      "   macro avg       0.77      0.79      0.78       602\n",
      "weighted avg       0.77      0.77      0.77       602\n",
      "\n",
      "\n",
      "ðŸ“Š Test (LogReg) Set\n",
      "Accuracy:  0.8713\n",
      "F1 Score:  0.8710\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.86      0.87       392\n",
      "     disgust       0.82      0.90      0.86       324\n",
      "        fear       0.88      0.94      0.91       317\n",
      "   happiness       0.88      0.82      0.85       545\n",
      "     neutral       0.89      0.83      0.86       679\n",
      "     sadness       0.84      0.94      0.89       331\n",
      "    surprise       0.89      0.88      0.89       420\n",
      "\n",
      "    accuracy                           0.87      3008\n",
      "   macro avg       0.87      0.88      0.87      3008\n",
      "weighted avg       0.87      0.87      0.87      3008\n",
      "\n",
      "\n",
      "ðŸ“Š Validation (NaiveBayes) Set\n",
      "Accuracy:  0.5199\n",
      "F1 Score:  0.5401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.26      0.88      0.40        68\n",
      "     disgust       1.00      0.59      0.74        61\n",
      "        fear       0.58      0.56      0.57        73\n",
      "   happiness       0.77      0.35      0.48       105\n",
      "     neutral       0.69      0.53      0.60       154\n",
      "     sadness       0.75      0.53      0.62        62\n",
      "    surprise       0.48      0.30      0.37        79\n",
      "\n",
      "    accuracy                           0.52       602\n",
      "   macro avg       0.65      0.54      0.54       602\n",
      "weighted avg       0.65      0.52      0.54       602\n",
      "\n",
      "\n",
      "ðŸ“Š Test (NaiveBayes) Set\n",
      "Accuracy:  0.5296\n",
      "F1 Score:  0.5430\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.29      0.86      0.44       392\n",
      "     disgust       0.90      0.52      0.66       324\n",
      "        fear       0.52      0.59      0.55       317\n",
      "   happiness       0.79      0.37      0.50       545\n",
      "     neutral       0.68      0.54      0.60       679\n",
      "     sadness       0.76      0.57      0.65       331\n",
      "    surprise       0.55      0.34      0.42       420\n",
      "\n",
      "    accuracy                           0.53      3008\n",
      "   macro avg       0.64      0.54      0.55      3008\n",
      "weighted avg       0.65      0.53      0.54      3008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12. Report\n",
    "val_acc_lr, val_f1_lr = evaluate(\"Validation (LogReg)\", y_val, val_preds_lr)\n",
    "test_acc_lr, test_f1_lr = evaluate(\"Test (LogReg)\", y_test, test_preds_lr)\n",
    "\n",
    "val_acc_nb, val_f1_nb = evaluate(\"Validation (NaiveBayes)\", y_val, val_preds_nb)\n",
    "test_acc_nb, test_f1_nb = evaluate(\"Test (NaiveBayes)\", y_test, test_preds_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74ef01e3-0cd8-44d2-bee6-cd10e1c3d8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.769103</td>\n",
       "      <td>0.767418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.519934</td>\n",
       "      <td>0.540139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.871343</td>\n",
       "      <td>0.870984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.529588</td>\n",
       "      <td>0.543039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model     Dataset  Accuracy  F1 Score\n",
       "0      LogReg  Validation  0.769103  0.767418\n",
       "1  NaiveBayes  Validation  0.519934  0.540139\n",
       "2      LogReg        Test  0.871343  0.870984\n",
       "3  NaiveBayes        Test  0.529588  0.543039"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Logistic Regression Params: {'C': 10, 'class_weight': 'balanced', 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best Naive Bayes Params: {'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# 13. Compare\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Model\": [\"LogReg\", \"NaiveBayes\", \"LogReg\", \"NaiveBayes\"],\n",
    "    \"Dataset\": [\"Validation\", \"Validation\", \"Test\", \"Test\"],\n",
    "    \"Accuracy\": [val_acc_lr, val_acc_nb, test_acc_lr, test_acc_nb],\n",
    "    \"F1 Score\": [val_f1_lr, val_f1_nb, test_f1_lr, test_f1_nb]\n",
    "})\n",
    "display(summary_df)\n",
    "\n",
    "# Optional: show best hyperparameters\n",
    "print(\"\\nBest Logistic Regression Params:\", lr_search.best_params_)\n",
    "print(\"Best Naive Bayes Params:\", nb_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
