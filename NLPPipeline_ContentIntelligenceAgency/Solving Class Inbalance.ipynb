{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 (Further Balancing Emotion Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage: Classifying emotions in transcribed television show data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from transformers import MarianMTModel, MarianTokenizer, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion\n",
       "happiness    24583\n",
       "surprise     10556\n",
       "sadness       7076\n",
       "neutral       6312\n",
       "anger         4971\n",
       "disgust       3587\n",
       "fear          1881\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript = \"transformers_dataset.csv\"\n",
    "df = pd.read_csv(transcript)\n",
    "\n",
    "# Display emotion classes\n",
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8423.714285714286\n"
     ]
    }
   ],
   "source": [
    "class_counts = df[\"Emotion\"].value_counts()\n",
    "print(class_counts.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding synthetic data to balance classes with the lowest nr of instances using Text Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also concatenating with the original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Augmentation:\n",
      " Emotion\n",
      "happiness    24583\n",
      "sadness      21191\n",
      "neutral      18403\n",
      "anger        14834\n",
      "disgust      10755\n",
      "surprise     10556\n",
      "fear          5526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from textattack.augmentation import EasyDataAugmenter\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize TextAttack augmenter (you can experiment with different ones)\n",
    "augmenter = EasyDataAugmenter(pct_words_to_swap=0.2, transformations_per_example=2)\n",
    "\n",
    "# Define a threshold: Augment only classes below this threshold\n",
    "THRESHOLD = 9000\n",
    "\n",
    "# Apply augmentation to underrepresented classes\n",
    "augmented_sentences = []\n",
    "augmented_labels = []\n",
    "\n",
    "for emotion, count in class_counts.items():\n",
    "    if count < THRESHOLD:\n",
    "        subset = df[df[\"Emotion\"] == emotion]\n",
    "        for sentence in subset[\"Sentence\"]:\n",
    "            augmented = augmenter.augment(sentence)\n",
    "            augmented_sentences.extend(augmented)\n",
    "            augmented_labels.extend([emotion] * len(augmented))\n",
    "\n",
    "# Create DataFrame for augmented data\n",
    "augmented_df = pd.DataFrame({\"Sentence\": augmented_sentences, \"Emotion\": augmented_labels})\n",
    "\n",
    "# Combine with original data\n",
    "df = pd.concat([df, augmented_df]).reset_index(drop=True)\n",
    "\n",
    "# Check new class distribution\n",
    "print(\"After Augmentation:\\n\", df[\"Emotion\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Sentence', 'Emotion']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "cleaned_file_path = \"../Task 4/balanced_classes_dataset.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
