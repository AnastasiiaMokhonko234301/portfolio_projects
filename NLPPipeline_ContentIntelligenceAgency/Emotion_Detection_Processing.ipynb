{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emotion Detection aims to classify a fine-grained emotion for each utterance in multiparty dialogue. Our annotation is based on the primary emotions in the Feeling Wheel (Willcox, 1982). We must admit that the inter-annotator agreement of this annotation is not the greatest; we welcome any contribution from the community to improve the annotation quality. This task is a part of the Character Mining project led by the Emory NLP research group.\n",
    "\n",
    "Github: https://github.com/emorynlp/emotion-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load JSON file\n",
    "with open(\"emotion-detection-emotion-detection-1.0/json/emotion-detection-trn.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "dataf = pd.DataFrame(data)\n",
    "\n",
    "# Expand the 'episodes' column\n",
    "episodes_list = []\n",
    "\n",
    "for _, row in dataf.iterrows():\n",
    "    season_id = row[\"season_id\"]  # Track season ID\n",
    "\n",
    "    # Check if the episodes column is a dictionary and process accordingly\n",
    "    if isinstance(row['episodes'], dict):  # If episodes is already a dict\n",
    "        episodes = [row['episodes']]  # Put it in a list for uniform processing\n",
    "    elif isinstance(row['episodes'], str):  # If episodes is a string, try parsing it\n",
    "        try:\n",
    "            episodes = json.loads(row['episodes'])  # Convert string to dictionary\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON for row {row.name}\")\n",
    "            continue\n",
    "    else:\n",
    "        episodes = []  # Empty list if structure is unexpected\n",
    "\n",
    "    # Iterate through the episodes\n",
    "    for episode in episodes:\n",
    "        # Make sure episode is a dictionary and has the expected keys\n",
    "        if isinstance(episode, dict) and \"episode_id\" in episode and \"scenes\" in episode:\n",
    "            episode_id = episode[\"episode_id\"]\n",
    "            for scene in episode[\"scenes\"]:\n",
    "                # Make sure each scene has the expected structure\n",
    "                if isinstance(scene, dict) and \"scene_id\" in scene and \"utterances\" in scene:\n",
    "                    scene_id = scene[\"scene_id\"]\n",
    "                    for utterance in scene[\"utterances\"]:\n",
    "                        if isinstance(utterance, dict) and \"utterance_id\" in utterance:\n",
    "                            episodes_list.append({\n",
    "                                \"season_id\": season_id,\n",
    "                                \"episode_id\": episode_id,\n",
    "                                \"scene_id\": scene_id,\n",
    "                                \"utterance_id\": utterance[\"utterance_id\"],\n",
    "                                \"speaker\": utterance[\"speakers\"][0] if utterance[\"speakers\"] else None,\n",
    "                                \"transcript\": utterance[\"transcript\"],\n",
    "                                \"emotion\": utterance[\"emotion\"]\n",
    "                            })\n",
    "        else:\n",
    "            print(f\"Unexpected episode structure: {episode}\")\n",
    "\n",
    "# Create a new DataFrame\n",
    "df = pd.DataFrame(episodes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset in case we need to restart the preprocessing\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>scene_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>transcript</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trn</td>\n",
       "      <td>s01_e02</td>\n",
       "      <td>s01_e02_c01</td>\n",
       "      <td>s01_e02_c01_u001</td>\n",
       "      <td>Monica Geller</td>\n",
       "      <td>What you guys don't understand is, for us, kis...</td>\n",
       "      <td>Joyful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trn</td>\n",
       "      <td>s01_e02</td>\n",
       "      <td>s01_e02_c01</td>\n",
       "      <td>s01_e02_c01_u002</td>\n",
       "      <td>Joey Tribbiani</td>\n",
       "      <td>Yeah, right!.......Y'serious?</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trn</td>\n",
       "      <td>s01_e02</td>\n",
       "      <td>s01_e02_c01</td>\n",
       "      <td>s01_e02_c01_u003</td>\n",
       "      <td>Phoebe Buffay</td>\n",
       "      <td>Oh, yeah!</td>\n",
       "      <td>Joyful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trn</td>\n",
       "      <td>s01_e02</td>\n",
       "      <td>s01_e02_c01</td>\n",
       "      <td>s01_e02_c01_u004</td>\n",
       "      <td>Rachel Green</td>\n",
       "      <td>Everything you need to know is in that first k...</td>\n",
       "      <td>Powerful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trn</td>\n",
       "      <td>s01_e02</td>\n",
       "      <td>s01_e02_c01</td>\n",
       "      <td>s01_e02_c01_u005</td>\n",
       "      <td>Monica Geller</td>\n",
       "      <td>Absolutely.</td>\n",
       "      <td>Powerful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  season_id episode_id     scene_id      utterance_id         speaker  \\\n",
       "0       trn    s01_e02  s01_e02_c01  s01_e02_c01_u001   Monica Geller   \n",
       "1       trn    s01_e02  s01_e02_c01  s01_e02_c01_u002  Joey Tribbiani   \n",
       "2       trn    s01_e02  s01_e02_c01  s01_e02_c01_u003   Phoebe Buffay   \n",
       "3       trn    s01_e02  s01_e02_c01  s01_e02_c01_u004    Rachel Green   \n",
       "4       trn    s01_e02  s01_e02_c01  s01_e02_c01_u005   Monica Geller   \n",
       "\n",
       "                                          transcript   emotion  \n",
       "0  What you guys don't understand is, for us, kis...    Joyful  \n",
       "1                      Yeah, right!.......Y'serious?   Neutral  \n",
       "2                                          Oh, yeah!    Joyful  \n",
       "3  Everything you need to know is in that first k...  Powerful  \n",
       "4                                        Absolutely.  Powerful  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season_id', 'episode_id', 'scene_id', 'utterance_id', 'speaker',\n",
       "       'transcript', 'emotion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unnecessary columns\n",
    "columns_to_keep = [\"transcript\", \"emotion\"]\n",
    "df_copy = df_copy[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          transcript   emotion\n",
      "0  What you guys don't understand is, for us, kis...    Joyful\n",
      "1                      Yeah, right!.......Y'serious?   Neutral\n",
      "2                                          Oh, yeah!    Joyful\n",
      "3  Everything you need to know is in that first k...  Powerful\n",
      "4                                        Absolutely.  Powerful\n"
     ]
    }
   ],
   "source": [
    "print(df_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joyful' 'Neutral' 'Powerful' 'Mad' 'Sad' 'Scared' 'Peaceful']\n"
     ]
    }
   ],
   "source": [
    "print(df_copy[\"emotion\"].unique())  # Show all unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace their 7 labels ('Joyful' 'Neutral' 'Powerful' 'Mad' 'Sad' 'Scared' 'Peaceful') \n",
    "# with our 7 labels (\"happiness\", \"sadness\", \"anger\", \"surprise\", \"fear\", \"disgust\", \"neutral\")\n",
    "df_copy.loc[:, \"emotion\"] = df_copy[\"emotion\"].str.replace(\"Joyful\", \"happiness\")\n",
    "df_copy.loc[:, \"emotion\"] = df_copy[\"emotion\"].str.replace(\"Neutral\", \"neutral\")\n",
    "df_copy.loc[:, \"emotion\"] = df_copy[\"emotion\"].str.replace(\"Powerful\", \"happiness\")\n",
    "df_copy.loc[:, \"emotion\"] = df_copy[\"emotion\"].str.replace(\"Mad\", \"anger\")\n",
    "df_copy.loc[:, \"emotion\"] = df_copy[\"emotion\"].str.replace(\"Sad\", \"sadness\")\n",
    "df_copy.loc[:, \"emotion\"] = df_copy[\"emotion\"].str.replace(\"Scared\", \"fear\")\n",
    "df_copy.loc[:, \"emotion\"] = df_copy[\"emotion\"].str.replace(\"Peaceful\", \"happiness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happiness' 'neutral' 'anger' 'sadness' 'fear']\n"
     ]
    }
   ],
   "source": [
    "print(df_copy[\"emotion\"].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What you guys don't understand is, for us, kis...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, right!.......Y'serious?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh, yeah!</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Everything you need to know is in that first k...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely.</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9929</th>\n",
       "      <td>Ahh, yes, I will have a glass of the Merlot</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9930</th>\n",
       "      <td>Okay.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9931</th>\n",
       "      <td>And uh, he will have a white wine spritzer.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9932</th>\n",
       "      <td>Okay, good. Thank you. I'll be back shortly, a...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9933</th>\n",
       "      <td>All right. Woo! Hey, look at that, the airport...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9934 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcript    emotion\n",
       "0     What you guys don't understand is, for us, kis...  happiness\n",
       "1                         Yeah, right!.......Y'serious?    neutral\n",
       "2                                             Oh, yeah!  happiness\n",
       "3     Everything you need to know is in that first k...  happiness\n",
       "4                                           Absolutely.  happiness\n",
       "...                                                 ...        ...\n",
       "9929        Ahh, yes, I will have a glass of the Merlot    neutral\n",
       "9930                                              Okay.    neutral\n",
       "9931        And uh, he will have a white wine spritzer.    neutral\n",
       "9932  Okay, good. Thank you. I'll be back shortly, a...  happiness\n",
       "9933  All right. Woo! Hey, look at that, the airport...       fear\n",
       "\n",
       "[9934 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the text column to resemble our transcribed dataset better\n",
    "df_copy.rename(columns={\"emotion\": \"Emotion\", \"transcript\": \"Sentence\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating: What you guys don't understand is, for us, kissing is as important as any part of it.\n",
      "Translating: Yeah, right!.......Y'serious?\n",
      "Translating: Oh, yeah!\n",
      "Translating: Everything you need to know is in that first kiss.\n",
      "Translating: Absolutely.\n",
      "Translating: Yeah, I think for us, kissing is pretty much like an opening act, y'know? I mean it's like the stand-up comedian you have to sit through before Pink Floyd comes out.\n",
      "Translating: Yeah, and-and it's not that we don't like the comedian, it's that-that... that's not why we bought the ticket.\n",
      "Translating: The problem is, though, after the concert's over, no matter how great the show was, you girls are always looking for the comedian again, y'know? I mean, we're in the car, we're fighting traffic... basically just trying to stay awake.\n",
      "Translating: Yeah, well, word of advice: Bring back the comedian. Otherwise next time you're gonna find yourself sitting at home, listening to that album alone.\n",
      "Translating: ....Are we still talking about sex?\n",
      "Translating: No, it's good, it is good, it's just that- mm- doesn't she seem a little angry?\n",
      "Translating: Well, she has issues.\n",
      "Translating: Does she.\n",
      "Translating: He's out banging other women over the head with a club, while she sits at home trying to get the mastodon smell out of the carpet!\n",
      "Translating: Marsha, these are cave people. Okay? They have issues like 'Gee, that glacier's getting kinda close.' See?\n",
      "Translating: Speaking of issues, isn't that your ex-wife?\n",
      "Translating: No. No.\n",
      "Translating: Yes, it is. Carol! Hi!\n",
      "Translating: Okay, okay, yes, it is. How about I'll, uh, catch up with you in the Ice Age.\n",
      "Translating: Hi.\n",
      "Translating: So.\n",
      "Translating: You look great. I, uh... I hate that.\n",
      "Translating: Sorry. You look good too.\n",
      "Translating: Ah, well, in here, anyone who... stands erect... So what's new? Still, uh...\n",
      "Translating: A lesbian?\n",
      "Translating: Well... you never know. How's, um.. how's the family?\n",
      "Translating: Marty's still totally paranoid. Oh, and, uh-\n",
      "Translating: Why- why are you here, Carol?\n",
      "Translating: I'm pregnant.\n",
      "Translating: Pregnant?!\n",
      "Translating: Sorry I'm late, I was stuck at work. There was this big dinosaur.. thing.. anyway.\n",
      "Translating: Hi.\n",
      "Translating: Ross, you remember Susan.\n",
      "Translating: How could I forget?\n",
      "Translating: Ross.\n",
      "Translating: Hello, Susan. Good shake. Good shake. So, uh, we're just waiting for...?\n",
      "Translating: Dr. Oberman.\n",
      "Translating: ..Dr. Oberman. Okay. And is he-\n",
      "Translating: She.\n",
      "Translating: -she, of course, she- uh- familiar with our.. special situation?\n",
      "Translating: Yes, and she's very supportive.\n",
      "Translating: Okay, that's great. No, I'm- Oh.\n",
      "Translating: Thanks.\n",
      "Translating: Quack, quack..\n",
      "Translating: Ross? That opens my cervix.\n",
      "Translating: Barry?\n",
      "Translating: C'mon in.\n",
      "Translating: Are you sure?\n",
      "Translating: Yeah! It's fine, it's fine. Robbie's gonna be here for hours.\n",
      "Translating: Huh?!\n",
      "Translating: So, how ya doin?\n",
      "Translating: I'm- uh- I'm okay... You look great!\n",
      "Translating: Yeah, well..\n",
      "Translating: Dr. Farber, Jason Greenstein's gagging.\n",
      "Translating: Be right there. Be back in a sec.\n",
      "Translating: I dumped him.\n",
      "Translating: Okay.\n",
      "Translating: So, um- so how's this, uh, how's this gonna work? Y'know, with us? Y'know, when, like, important decisions have to be made?\n",
      "Translating: Give me a 'for instance'.\n",
      "Translating: Well, uh, uh, I don't know, okay, okay, how about with the, uh, with the baby's name?\n",
      "Translating: Marlon-\n",
      "Translating: Marlon?!\n",
      "Translating: -if it's a boy, Minnie if it's a girl.\n",
      "Translating: ...As in Mouse?\n",
      "Translating: As in my grandmother.\n",
      "Translating: Still, you- you say Minnie, you hear Mouse. Um, how about, um.. how about Julia?\n",
      "Translating: Julia..\n",
      "Translating: We agreed on Minnie.\n",
      "Translating: 'S'funny, um, uh, we agreed we'd spend the rest of our lives together. Things change, roll with the punches. I believe Julia's on the table..?\n",
      "Translating: Sorry about that. So. What have you been up to?\n",
      "Translating: Oh, not much. I-I got a job.\n",
      "Translating: Oh, that's great.\n",
      "Translating: Why are- why are you so tanned?\n",
      "Translating: Oh, I, uh- I went to Aruba.\n",
      "Translating: Oh no. You went on our honeymoon alone?\n",
      "Translating: No. I went with, uh.. Now, this may hurt.\n",
      "Translating: Me?!\n",
      "Translating: No! I went with Mindy.\n",
      "Translating: Mindy?! My maid of honour, Mindy?!\n",
      "Translating: Yeah, well, uh, we're kind of a thing now.\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "import time\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "def translate_function(text):\n",
    "    try:\n",
    "        print(f\"Translating: {text}\")  # Add this to see if the function is being called\n",
    "        if not isinstance(text, str) or text.strip() == \"\":\n",
    "            print(f\"Skipping invalid input: {text}\")\n",
    "            return text\n",
    "        \n",
    "        time.sleep(0.5)  # Avoid rate limits\n",
    "        translated_text = translator.translate(text, dest=\"fr\").text  # This should be synchronous\n",
    "        \n",
    "        if not translated_text:\n",
    "            print(f\"Empty translation for: {text}\")\n",
    "            return text  \n",
    "\n",
    "        return translated_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error translating: {text} - {e}\")\n",
    "        return text\n",
    "\n",
    "# Apply the translation function to the \"Sentence\" column\n",
    "df_copy[\"Translated\"] = df_copy[\"Sentence\"].apply(translate_function)\n",
    "\n",
    "# Now df_sampled will have the \"Translated\" column with the French translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv('emory_nlp_ds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
